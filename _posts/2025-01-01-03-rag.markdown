---
layout: post
title: Simple Rag
category: ""
---

# Install pyenv

```sh

sudo yum install gcc zlib-devel bzip2 bzip2-devel readline readline-devel sqlite sqlite-devel openssl openssl-devel git libffi-devel

git clone https://github.com/pyenv/pyenv.git ~/.pyenv

if grep "pyenv init -" ~/.bash_profile ] ; then
  echo "skip."
else
  echo 'export PATH="$HOME/.pyenv/bin:$PATH"' >> ~/.bash_profile
  echo 'eval "$(pyenv init -)"' >> ~/.bash_profile
fi
source ~/.bash_profile

pyenv install --list
pyver="3.13.5"
pyenv install ${pyver}
pyenv global  ${pyver}

pyenv rehash
```

# Install sqlite3 for ChromaDB

```sh
curl -O https://www.sqlite.org/2025/sqlite-src-3500200.zip
unzip sqlite-src-3500200.zip
cd sqlite-src-3500200/
./configure && make
sudo make install

export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
```

# project dir

```sh
mkdir rag
cd $_

cat <<'EOF' > requirements.txt
langchain
ollama
faiss-cpu
langchain-community
langchain-ollama
EOF

pip3.13 install -r requirements.txt

mkdir docs

cat <<'EOF' > docs/text.md
* çŒ«ã¯ãƒ‹ãƒ£ãƒ¼
* çŠ¬ãªã‚‰ãƒ¯ãƒ³
* è±¡ã¯ãƒ‘ã‚ªãƒ¼ãƒ³
* ãƒ©ã‚¤ã‚ªãƒ³ã‚¬ã‚ªãƒ¼ãƒƒ
* äººé–“ã ã‚‚ã‚“ã‚ã‹ã•ãŸãªã¯ã‚„ã¾ã‚‰ã‚ãŠã‚“
EOF
ollama pull gemma3n
```

# Script

```sh
cat <<'EOF' > build_index3.py
import glob
from langchain_community.vectorstores import FAISS
from langchain_ollama import OllamaEmbeddings, OllamaLLM
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain.chains import RetrievalQA

# ---------- è¨­å®š ----------
EMBED_MODEL = "nomic-embed-text"
LLM_MODEL = "gemma3n"
DOC_PATTERN = "docs/*.md"
QUERY = "çŠ¬ã¯ï¼Ÿ"

# ---------- Markdownãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ----------
file_paths = glob.glob(DOC_PATTERN)
all_docs = []

for path in file_paths:
    loader = TextLoader(path, encoding="utf-8")
    docs = loader.load()
    for doc in docs:
        doc.metadata["source"] = path  # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¨˜éŒ²
    all_docs.extend(docs)

print(f"âœ… èª­ã¿è¾¼ã‚“ã ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_paths)}")
print(f"âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(all_docs)}")

# ---------- åˆ†å‰² ----------
splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_docs = splitter.split_documents(all_docs)
print(f"âœ… ãƒãƒ£ãƒ³ã‚¯æ•°: {len(split_docs)}")

# ---------- åŸ‹ã‚è¾¼ã¿ã¨ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢æ§‹ç¯‰ ----------
embedder = OllamaEmbeddings(model=EMBED_MODEL)
vectorstore = FAISS.from_documents(split_docs, embedder)

# ---------- Retriever & LLM ----------
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
llm = OllamaLLM(model=LLM_MODEL)

# ---------- RetrievalQAãƒã‚§ãƒ¼ãƒ³ ----------
rag_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    return_source_documents=True
)

# ---------- è³ªå• ----------
print(f"\nâ“ è³ªå•: {QUERY}")
result = rag_chain.invoke({"query": QUERY})

# ---------- å‡ºåŠ› ----------
print("\nğŸ§  å›ç­”:\n", result["result"])

print("\nğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹:")
for doc in result["source_documents"]:
    print(f"- {doc.metadata.get('source', 'ä¸æ˜')}")
    print(doc.page_content[:100].replace("\n", " "), "\n---")

EOF
```

## Execution

```sh
python3.13 build_index3.py
```

### Outcome

```
user@y ~/rag$ python3.13 build_index3.py 
âœ… èª­ã¿è¾¼ã‚“ã ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 1
âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: 1
âœ… ãƒãƒ£ãƒ³ã‚¯æ•°: 1

â“ è³ªå•: çŠ¬ã¯ï¼Ÿ

ğŸ§  å›ç­”:
 çŠ¬ãªã‚‰ãƒ¯ãƒ³


ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹:
- docs/a.md
çŒ«ã¯ãƒ‹ãƒ£ãƒ¼ çŠ¬ãªã‚‰ãƒ¯ãƒ³ è±¡ã¯ãƒ‘ã‚ªãƒ¼ãƒ³ ãƒ©ã‚¤ã‚ªãƒ³ã‚¬ã‚ªãƒ¼ãƒƒ äººé–“ã ã‚‚ã‚“ã‚ã‹ã•ãŸãªã¯ã‚„ã¾ã‚‰ã‚ãŠã‚“ 
---
user@y ~/rag$ 
```
